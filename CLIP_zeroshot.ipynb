{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "82439cbc685a4a899582bd9866f2d009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4c6b03242534480a17b604bd1424408",
              "IPY_MODEL_c40c44cc95de412aaebef07c60b7c5a4",
              "IPY_MODEL_e03552a12743477dbefb9cf934becebb"
            ],
            "layout": "IPY_MODEL_d3e4f627ff374436a87acf59470b1c4e"
          }
        },
        "b4c6b03242534480a17b604bd1424408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_373cc5b2752f4378b35cca9051373f9a",
            "placeholder": "​",
            "style": "IPY_MODEL_d35aa8604aaa4d619e6da2822dc85d41",
            "value": "100%"
          }
        },
        "c40c44cc95de412aaebef07c60b7c5a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33a56bb33f554ba7b6c3f434f590e5c3",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_938db2c42a47486ca6e463dc1ef3f9ff",
            "value": 100
          }
        },
        "e03552a12743477dbefb9cf934becebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1beeb488b8e44446830f852e2eade938",
            "placeholder": "​",
            "style": "IPY_MODEL_e335336eda5044118cb1f0705af573d9",
            "value": " 100/100 [00:06&lt;00:00, 18.69it/s]"
          }
        },
        "d3e4f627ff374436a87acf59470b1c4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "373cc5b2752f4378b35cca9051373f9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d35aa8604aaa4d619e6da2822dc85d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33a56bb33f554ba7b6c3f434f590e5c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "938db2c42a47486ca6e463dc1ef3f9ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1beeb488b8e44446830f852e2eade938": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e335336eda5044118cb1f0705af573d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9185544940c846ecb642817ef566cae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69b4511135404188b413ac2603fe7062",
              "IPY_MODEL_c80978c377114872bfda38597ab69640",
              "IPY_MODEL_14c99e36ab354774969d3d1c4487d16f"
            ],
            "layout": "IPY_MODEL_4c28d8851c41499db1464edeb89cd538"
          }
        },
        "69b4511135404188b413ac2603fe7062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d79824a4e6b4dfc86a97c50afc7751e",
            "placeholder": "​",
            "style": "IPY_MODEL_c7aef723369248898475b74b8e96d120",
            "value": "100%"
          }
        },
        "c80978c377114872bfda38597ab69640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62e2018730b9424bb0a85ae7c1467358",
            "max": 78,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8246ae9a628741e0b8bc5648ac8cf105",
            "value": 78
          }
        },
        "14c99e36ab354774969d3d1c4487d16f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_271001151d274af38718df2a53110e2f",
            "placeholder": "​",
            "style": "IPY_MODEL_1e99f2caa9f84004b89800a69e394d7c",
            "value": " 78/78 [00:11&lt;00:00, 10.39it/s]"
          }
        },
        "4c28d8851c41499db1464edeb89cd538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d79824a4e6b4dfc86a97c50afc7751e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7aef723369248898475b74b8e96d120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62e2018730b9424bb0a85ae7c1467358": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8246ae9a628741e0b8bc5648ac8cf105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "271001151d274af38718df2a53110e2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e99f2caa9f84004b89800a69e394d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oz-e/applied-ml/blob/main/CLIP_zeroshot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53N4k0pj_9qL"
      },
      "source": [
        "# Preparation for Colab\n",
        "\n",
        "Make sure you're running a GPU runtime; if not, select \"GPU\" as the hardware accelerator in Runtime > Change Runtime Type in the menu. The next cells will install the `clip` package and its dependencies, and check if PyTorch 1.7.1 or later is installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BpdJkdBssk9",
        "outputId": "a2be67e9-3189-47d5-f5c3-317e49155cd6"
      },
      "source": [
        "# Change the path if necessary\n",
        "datasets_path = 'datasets'\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Deploy AML code in colab\n",
        "if 'google.colab' in sys.modules:\n",
        "  if not os.path.exists('/content/applied-ml/'):\n",
        "    !wget -q https://raw.githubusercontent.com/tsunrise/colab-github/main/colab_github.py\n",
        "    import colab_github\n",
        "    colab_github.github_auth(persistent_key=False)\n",
        "\n",
        "    !git clone git@github.com:oz-e/applied-ml.git\n",
        "    if not os.path.exists('/content/applied-ml/'):\n",
        "      raise Exception('Please follow the instructions to add the SSH key to your account in order to clone private repo')\n",
        "  %cd /content/applied-ml/\n",
        "\n",
        "  # Install any other requirements in colab (to be converted to requirements.txt)\n",
        "  !pip install openai-clip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looks that a private key is already created. If you have already push it to github, no action required.\n",
            " Otherwise, Please go to https://github.com/settings/ssh/new to upload the following key: \n",
            "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIICcUHCb4rUSbumpmY28DXFrETHqzcIzNIIapzj+1Izu root@534e7347ece2\n",
            "\n",
            "Please use SSH method to clone repo.\n",
            "Cloning into 'applied-ml'...\n",
            "remote: Enumerating objects: 118, done.\u001b[K\n",
            "remote: Counting objects: 100% (118/118), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 118 (delta 66), reused 18 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (118/118), 1.93 MiB | 9.72 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n",
            "/content/applied-ml\n",
            "Collecting openai-clip\n",
            "  Downloading openai-clip-1.0.1.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from openai-clip)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from openai-clip) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-clip) (4.67.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->openai-clip) (0.2.13)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-clip\n",
            "  Building wheel for openai-clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-clip: filename=openai_clip-1.0.1-py3-none-any.whl size=1368605 sha256=967611662472cba9e99a7393906762bc4986399cc6f7fa41a8a43ca9c472269f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/17/90/042948fd2e2a87f1dcf6db6d438cad015c49db0c53d1d9c7dc\n",
            "Successfully built openai-clip\n",
            "Installing collected packages: ftfy, openai-clip\n",
            "Successfully installed ftfy-6.3.1 openai-clip-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1hkDT38hSaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c64089f9-74c2-4fb5-858a-519361542afd"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import clip\n",
        "from tqdm.notebook import tqdm\n",
        "from pkg_resources import packaging\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFxgLV5HAEEw"
      },
      "source": [
        "# Loading the model\n",
        "\n",
        "Download and instantiate a CLIP model using the `clip` module that we just installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLFS29hnhlY4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e264b3-2f08-4383-abbf-ebb8d226ecd2"
      },
      "source": [
        "clip.available_models()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RN50',\n",
              " 'RN101',\n",
              " 'RN50x4',\n",
              " 'RN50x16',\n",
              " 'RN50x64',\n",
              " 'ViT-B/32',\n",
              " 'ViT-B/16',\n",
              " 'ViT-L/14',\n",
              " 'ViT-L/14@336px']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cboKZocQlSYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "576b0d01-1e36-4d70-ef1e-e8ac18349710"
      },
      "source": [
        "model, preprocess = clip.load(\"ViT-B/16\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 335M/335M [00:16<00:00, 21.4MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBRVTY9lbGm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95467259-b7e3-4857-b1d1-080179fc106b"
      },
      "source": [
        "input_resolution = model.visual.input_resolution\n",
        "context_length = model.context_length\n",
        "vocab_size = model.vocab_size\n",
        "\n",
        "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
        "print(\"Input resolution:\", input_resolution)\n",
        "print(\"Context length:\", context_length)\n",
        "print(\"Vocab size:\", vocab_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: 149,620,737\n",
            "Input resolution: 224\n",
            "Context length: 77\n",
            "Vocab size: 49408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhO3OtOmF8M4"
      },
      "source": [
        "# Preparing ImageNet labels and prompts\n",
        "\n",
        "The following cell contains the 1,000 labels for the ImageNet dataset, followed by the text templates we'll use as \"prompt engineering\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2HbOZrqa0jF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0763b01-3c1a-4f90-9932-10638644f8fd"
      },
      "source": [
        "import aml.datasets\n",
        "\n",
        "images = aml.datasets.Caltech101(datasets_path, split='test', transform=preprocess)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=137RyRjvTBkBiIfeYBNZBtViDHQ6_Ewsp\n",
            "From (redirected): https://drive.usercontent.google.com/download?id=137RyRjvTBkBiIfeYBNZBtViDHQ6_Ewsp&confirm=t&uuid=88d97627-5ec2-46c2-9942-b923ecaef6dc\n",
            "To: /content/applied-ml/datasets/caltech101/101_ObjectCategories.tar.gz\n",
            "100%|██████████| 132M/132M [00:01<00:00, 94.2MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=175kQy3UsZ0wUEHZjqkUDdNVssr7bgh_m\n",
            "From (redirected): https://drive.usercontent.google.com/download?id=175kQy3UsZ0wUEHZjqkUDdNVssr7bgh_m&confirm=t&uuid=ec8085d0-c92e-4be9-ae6c-7c148f7ac9bb\n",
            "To: /content/applied-ml/datasets/caltech101/Annotations.tar\n",
            "100%|██████████| 14.0M/14.0M [00:00<00:00, 170MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hyarUivQE36mY6jSomru6Fjd-JzwcCzN\n",
            "To: /content/applied-ml/datasets/caltech101/split.json\n",
            "100%|██████████| 809k/809k [00:00<00:00, 124MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imagenet_classes = images.classnames\n",
        "print(imagenet_classes)"
      ],
      "metadata": {
        "id": "Fe4vulwzDTL4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb59904-b696-44b0-95f0-40cfc4dfb1e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['face', 'leopard', 'motorbike', 'accordion', 'airplane', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMQSCuBta2G6"
      },
      "source": [
        "A subset of these class names are modified from the default ImageNet class names sourced from Anish Athalye's imagenet-simple-labels.\n",
        "\n",
        "These edits were made via trial and error and concentrated on the lowest performing classes according to top_1 and top_5 accuracy on the ImageNet training set for the RN50, RN101, and RN50x4 models. These tweaks improve top_1 by 1.5% on ViT-B/32 over using the default class names. Alec got bored somewhere along the way as gains started to diminish and never finished updating / tweaking the list. He also didn't revisit this with the better performing RN50x16, RN50x64, or any of the ViT models. He thinks it's likely another 0.5% to 1% top_1 could be gained from further work here. It'd be interesting to more rigorously study / understand this.\n",
        "\n",
        "Some examples beyond the crane/crane -> construction crane / bird crane issue mentioned in Section 3.1.4 of the paper include:\n",
        "\n",
        "- CLIP interprets \"nail\" as \"fingernail\" so we changed the label to \"metal nail\".\n",
        "- ImageNet kite class refers to the bird of prey, not the flying toy, so we changed \"kite\" to \"kite (bird of prey)\"\n",
        "- The ImageNet class for red wolf seems to include a lot of mislabeled maned wolfs so we changed \"red wolf\" to \"red wolf or maned wolf\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toGtcd-Ji_MD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a1e370a-b0bc-495c-a134-ed19ffc90ef7"
      },
      "source": [
        "imagenet_templates = [\n",
        "    'a bad photo of a {}.',\n",
        "    'a photo of many {}.',\n",
        "    'a sculpture of a {}.',\n",
        "    'a photo of the hard to see {}.',\n",
        "    'a low resolution photo of the {}.',\n",
        "    'a rendering of a {}.',\n",
        "    'graffiti of a {}.',\n",
        "    'a bad photo of the {}.',\n",
        "    'a cropped photo of the {}.',\n",
        "    'a tattoo of a {}.',\n",
        "    'the embroidered {}.',\n",
        "    'a photo of a hard to see {}.',\n",
        "    'a bright photo of a {}.',\n",
        "    'a photo of a clean {}.',\n",
        "    'a photo of a dirty {}.',\n",
        "    'a dark photo of the {}.',\n",
        "    'a drawing of a {}.',\n",
        "    'a photo of my {}.',\n",
        "    'the plastic {}.',\n",
        "    'a photo of the cool {}.',\n",
        "    'a close-up photo of a {}.',\n",
        "    'a black and white photo of the {}.',\n",
        "    'a painting of the {}.',\n",
        "    'a painting of a {}.',\n",
        "    'a pixelated photo of the {}.',\n",
        "    'a sculpture of the {}.',\n",
        "    'a bright photo of the {}.',\n",
        "    'a cropped photo of a {}.',\n",
        "    'a plastic {}.',\n",
        "    'a photo of the dirty {}.',\n",
        "    'a jpeg corrupted photo of a {}.',\n",
        "    'a blurry photo of the {}.',\n",
        "    'a photo of the {}.',\n",
        "    'a good photo of the {}.',\n",
        "    'a rendering of the {}.',\n",
        "    'a {} in a video game.',\n",
        "    'a photo of one {}.',\n",
        "    'a doodle of a {}.',\n",
        "    'a close-up photo of the {}.',\n",
        "    'a photo of a {}.',\n",
        "    'the origami {}.',\n",
        "    'the {} in a video game.',\n",
        "    'a sketch of a {}.',\n",
        "    'a doodle of the {}.',\n",
        "    'a origami {}.',\n",
        "    'a low resolution photo of a {}.',\n",
        "    'the toy {}.',\n",
        "    'a rendition of the {}.',\n",
        "    'a photo of the clean {}.',\n",
        "    'a photo of a large {}.',\n",
        "    'a rendition of a {}.',\n",
        "    'a photo of a nice {}.',\n",
        "    'a photo of a weird {}.',\n",
        "    'a blurry photo of a {}.',\n",
        "    'a cartoon {}.',\n",
        "    'art of a {}.',\n",
        "    'a sketch of the {}.',\n",
        "    'a embroidered {}.',\n",
        "    'a pixelated photo of a {}.',\n",
        "    'itap of the {}.',\n",
        "    'a jpeg corrupted photo of the {}.',\n",
        "    'a good photo of a {}.',\n",
        "    'a plushie {}.',\n",
        "    'a photo of the nice {}.',\n",
        "    'a photo of the small {}.',\n",
        "    'a photo of the weird {}.',\n",
        "    'the cartoon {}.',\n",
        "    'art of the {}.',\n",
        "    'a drawing of the {}.',\n",
        "    'a photo of the large {}.',\n",
        "    'a black and white photo of a {}.',\n",
        "    'the plushie {}.',\n",
        "    'a dark photo of a {}.',\n",
        "    'itap of a {}.',\n",
        "    'graffiti of the {}.',\n",
        "    'a toy {}.',\n",
        "    'itap of my {}.',\n",
        "    'a photo of a cool {}.',\n",
        "    'a photo of a small {}.',\n",
        "    'a tattoo of the {}.',\n",
        "]\n",
        "\n",
        "print(f\"{len(imagenet_classes)} classes, {len(imagenet_templates)} templates\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 classes, 80 templates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRB5OzgpHwqQ"
      },
      "source": [
        "A similar, intuition-guided trial and error based on the ImageNet training set was used for templates. This list is pretty haphazard and was gradually made / expanded over the course of about a year of the project and was revisited / tweaked every few months. A surprising / weird thing was adding templates intended to help ImageNet-R performance (specifying different possible renditions of an object) improved standard ImageNet accuracy too.\n",
        "\n",
        "After the 80 templates were \"locked\" for the paper, we ran sequential forward selection over the list of 80 templates. The search terminated after ensembling 7 templates and selected them in the order below.\n",
        "\n",
        "1. itap of a {}.\n",
        "2. a bad photo of the {}.\n",
        "3. a origami {}.\n",
        "4. a photo of the large {}.\n",
        "5. a {} in a video game.\n",
        "6. art of the {}.\n",
        "7. a photo of the small {}.\n",
        "\n",
        "Speculating, we think it's interesting to see different scales (large and small), a difficult view (a bad photo), and \"abstract\" versions (origami, video game, art), were all selected for, but we haven't studied this in any detail. This subset performs a bit better than the full 80 ensemble reported in the paper, especially for the smaller models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W8ARJVqBJXs"
      },
      "source": [
        "# Loading the Images\n",
        "\n",
        "The ILSVRC2012 datasets are no longer available for download publicly. We instead download the ImageNet-V2 dataset by [Recht et al.](https://arxiv.org/abs/1902.10811).\n",
        "\n",
        "If you have the ImageNet dataset downloaded, you can replace the dataset with the official torchvision loader, e.g.:\n",
        "\n",
        "```python\n",
        "images = torchvision.datasets.ImageNet(\"path/to/imagenet\", split='val', transform=preprocess)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moHR4UlHKsDc"
      },
      "source": [
        "loader = torch.utils.data.DataLoader(images, batch_size=32, num_workers=2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz6D-F-Wbrtp"
      },
      "source": [
        "# Creating zero-shot classifier weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRqDoz1Gbsii",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "82439cbc685a4a899582bd9866f2d009",
            "b4c6b03242534480a17b604bd1424408",
            "c40c44cc95de412aaebef07c60b7c5a4",
            "e03552a12743477dbefb9cf934becebb",
            "d3e4f627ff374436a87acf59470b1c4e",
            "373cc5b2752f4378b35cca9051373f9a",
            "d35aa8604aaa4d619e6da2822dc85d41",
            "33a56bb33f554ba7b6c3f434f590e5c3",
            "938db2c42a47486ca6e463dc1ef3f9ff",
            "1beeb488b8e44446830f852e2eade938",
            "e335336eda5044118cb1f0705af573d9"
          ]
        },
        "outputId": "fed05929-95ab-4805-a3b5-fe44b7f00cb1"
      },
      "source": [
        "def zeroshot_classifier(classnames, templates):\n",
        "    with torch.no_grad():\n",
        "        zeroshot_weights = []\n",
        "        for classname in tqdm(classnames):\n",
        "            texts = [template.format(classname) for template in templates] #format with class\n",
        "            texts = clip.tokenize(texts).cuda() #tokenize\n",
        "            class_embeddings = model.encode_text(texts) #embed with text encoder\n",
        "            class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
        "            class_embedding = class_embeddings.mean(dim=0)\n",
        "            class_embedding /= class_embedding.norm()\n",
        "            zeroshot_weights.append(class_embedding)\n",
        "        zeroshot_weights = torch.stack(zeroshot_weights, dim=1).cuda()\n",
        "    return zeroshot_weights\n",
        "\n",
        "\n",
        "zeroshot_weights = zeroshot_classifier(imagenet_classes, imagenet_templates)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82439cbc685a4a899582bd9866f2d009"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fZo7hG8iJP5"
      },
      "source": [
        "# Zero-shot prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4kPSZoShQxN"
      },
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    pred = output.topk(max(topk), 1, True, True)[1].t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "    return [float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy()) for k in topk]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKJ7YsdlkDXo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "9185544940c846ecb642817ef566cae3",
            "69b4511135404188b413ac2603fe7062",
            "c80978c377114872bfda38597ab69640",
            "14c99e36ab354774969d3d1c4487d16f",
            "4c28d8851c41499db1464edeb89cd538",
            "5d79824a4e6b4dfc86a97c50afc7751e",
            "c7aef723369248898475b74b8e96d120",
            "62e2018730b9424bb0a85ae7c1467358",
            "8246ae9a628741e0b8bc5648ac8cf105",
            "271001151d274af38718df2a53110e2f",
            "1e99f2caa9f84004b89800a69e394d7c"
          ]
        },
        "outputId": "f2847458-dd94-4717-987a-4b556a4114ac"
      },
      "source": [
        "with torch.no_grad():\n",
        "    top1, top5, n = 0., 0., 0.\n",
        "    for i, (images, target) in enumerate(tqdm(loader)):\n",
        "        images = images.cuda()\n",
        "        target = target.cuda()\n",
        "\n",
        "        # predict\n",
        "        image_features = model.encode_image(images)\n",
        "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "        logits = 100. * image_features @ zeroshot_weights\n",
        "\n",
        "        # measure accuracy\n",
        "        acc1, acc5 = accuracy(logits, target, topk=(1, 5))\n",
        "        top1 += acc1\n",
        "        top5 += acc5\n",
        "        n += images.size(0)\n",
        "\n",
        "top1 = (top1 / n) * 100\n",
        "top5 = (top5 / n) * 100\n",
        "\n",
        "print(f\"Top-1 accuracy: {top1:.2f}\")\n",
        "print(f\"Top-5 accuracy: {top5:.2f}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/78 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9185544940c846ecb642817ef566cae3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-e5b7f54f8676>:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  return [float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy()) for k in topk]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 accuracy: 92.98\n",
            "Top-5 accuracy: 99.72\n"
          ]
        }
      ]
    }
  ]
}